{"cells":[{"cell_type":"code","execution_count":null,"id":"7c6e04ed","metadata":{"id":"7c6e04ed"},"outputs":[],"source":["root_dir = '/data/ChaochaoData/DSA-DL/HyperMorph/'\n","workspace = root_dir + 'HM_PS_likert/'\n","util_dir = '/data/ChaochaoData/DSA-DL/Utilities/'\n","train_dir = '/data/ChaochaoData/PixShift/DataSets/PaperData/CombinedTrain'\n","test_dir = '/data/ChaochaoData/PixShift/DataSets/PaperData/CombinedTest'\n","cm_train_dir = '/data/ChaochaoData/ClearMatch/nifti_predictions/train_dataset'\n","cm_test_dir = '/data/ChaochaoData/ClearMatch/nifti_predictions/test_dataset'"]},{"cell_type":"code","execution_count":null,"id":"39f1aa85","metadata":{"id":"39f1aa85","outputId":"53f60463-433f-40e5-9c45-cd63995fd566"},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-06-02 00:50:59.296654: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"]},{"data":{"text/html":["<style>\n","        .bk-notebook-logo {\n","            display: block;\n","            width: 20px;\n","            height: 20px;\n","            background-image: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAABx0RVh0U29mdHdhcmUAQWRvYmUgRmlyZXdvcmtzIENTNui8sowAAAOkSURBVDiNjZRtaJVlGMd/1/08zzln5zjP1LWcU9N0NkN8m2CYjpgQYQXqSs0I84OLIC0hkEKoPtiH3gmKoiJDU7QpLgoLjLIQCpEsNJ1vqUOdO7ppbuec5+V+rj4ctwzd8IIbbi6u+8f1539dt3A78eXC7QizUF7gyV1fD1Yqg4JWz84yffhm0qkFqBogB9rM8tZdtwVsPUhWhGcFJngGeWrPzHm5oaMmkfEg1usvLFyc8jLRqDOMru7AyC8saQr7GG7f5fvDeH7Ej8CM66nIF+8yngt6HWaKh7k49Soy9nXurCi1o3qUbS3zWfrYeQDTB/Qj6kX6Ybhw4B+bOYoLKCC9H3Nu/leUTZ1JdRWkkn2ldcCamzrcf47KKXdAJllSlxAOkRgyHsGC/zRday5Qld9DyoM4/q/rUoy/CXh3jzOu3bHUVZeU+DEn8FInkPBFlu3+nW3Nw0mk6vCDiWg8CeJaxEwuHS3+z5RgY+YBR6V1Z1nxSOfoaPa4LASWxxdNp+VWTk7+4vzaou8v8PN+xo+KY2xsw6une2frhw05CTYOmQvsEhjhWjn0bmXPjpE1+kplmmkP3suftwTubK9Vq22qKmrBhpY4jvd5afdRA3wGjFAgcnTK2s4hY0/GPNIb0nErGMCRxWOOX64Z8RAC4oCXdklmEvcL8o0BfkNK4lUg9HTl+oPlQxdNo3Mg4Nv175e/1LDGzZen30MEjRUtmXSfiTVu1kK8W4txyV6BMKlbgk3lMwYCiusNy9fVfvvwMxv8Ynl6vxoByANLTWplvuj/nF9m2+PDtt1eiHPBr1oIfhCChQMBw6Aw0UulqTKZdfVvfG7VcfIqLG9bcldL/+pdWTLxLUy8Qq38heUIjh4XlzZxzQm19lLFlr8vdQ97rjZVOLf8nclzckbcD4wxXMidpX30sFd37Fv/GtwwhzhxGVAprjbg0gCAEeIgwCZyTV2Z1REEW8O4py0wsjeloKoMr6iCY6dP92H6Vw/oTyICIthibxjm/DfN9lVz8IqtqKYLUXfoKVMVQVVJOElGjrnnUt9T9wbgp8AyYKaGlqingHZU/uG2NTZSVqwHQTWkx9hxjkpWDaCg6Ckj5qebgBVbT3V3NNXMSiWSDdGV3hrtzla7J+duwPOToIg42ChPQOQjspnSlp1V+Gjdged7+8UN5CRAV7a5EdFNwCjEaBR27b3W890TE7g24NAP/mMDXRWrGoFPQI9ls/MWO2dWFAar/xcOIImbbpA3zgAAAABJRU5ErkJggg==);\n","        }\n","    </style>\n","    <div>\n","        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-notebook-logo\"></a>\n","        <span id=\"bc69267f-5dbb-440a-a604-56a5cca73d73\">Loading BokehJS ...</span>\n","    </div>\n"]},"metadata":{},"output_type":"display_data"},{"data":{"application/javascript":"(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\nconst JS_MIME_TYPE = 'application/javascript';\n  const HTML_MIME_TYPE = 'text/html';\n  const EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n  const CLASS_NAME = 'output_bokeh rendered_html';\n\n  /**\n   * Render data to the DOM node\n   */\n  function render(props, node) {\n    const script = document.createElement(\"script\");\n    node.appendChild(script);\n  }\n\n  /**\n   * Handle when an output is cleared or removed\n   */\n  function handleClearOutput(event, handle) {\n    const cell = handle.cell;\n\n    const id = cell.output_area._bokeh_element_id;\n    const server_id = cell.output_area._bokeh_server_id;\n    // Clean up Bokeh references\n    if (id != null && id in Bokeh.index) {\n      Bokeh.index[id].model.document.clear();\n      delete Bokeh.index[id];\n    }\n\n    if (server_id !== undefined) {\n      // Clean up Bokeh references\n      const cmd_clean = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n      cell.notebook.kernel.execute(cmd_clean, {\n        iopub: {\n          output: function(msg) {\n            const id = msg.content.text.trim();\n            if (id in Bokeh.index) {\n              Bokeh.index[id].model.document.clear();\n              delete Bokeh.index[id];\n            }\n          }\n        }\n      });\n      // Destroy server and session\n      const cmd_destroy = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n      cell.notebook.kernel.execute(cmd_destroy);\n    }\n  }\n\n  /**\n   * Handle when a new output is added\n   */\n  function handleAddOutput(event, handle) {\n    const output_area = handle.output_area;\n    const output = handle.output;\n\n    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n      return\n    }\n\n    const toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n\n    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n      // store reference to embed id on output_area\n      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n    }\n    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n      const bk_div = document.createElement(\"div\");\n      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n      const script_attrs = bk_div.children[0].attributes;\n      for (let i = 0; i < script_attrs.length; i++) {\n        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n      }\n      // store reference to server id on output_area\n      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n    }\n  }\n\n  function register_renderer(events, OutputArea) {\n\n    function append_mime(data, metadata, element) {\n      // create a DOM node to render to\n      const toinsert = this.create_output_subarea(\n        metadata,\n        CLASS_NAME,\n        EXEC_MIME_TYPE\n      );\n      this.keyboard_manager.register_events(toinsert);\n      // Render to node\n      const props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n      render(props, toinsert[toinsert.length - 1]);\n      element.append(toinsert);\n      return toinsert\n    }\n\n    /* Handle when an output is cleared or removed */\n    events.on('clear_output.CodeCell', handleClearOutput);\n    events.on('delete.Cell', handleClearOutput);\n\n    /* Handle when a new output is added */\n    events.on('output_added.OutputArea', handleAddOutput);\n\n    /**\n     * Register the mime type and append_mime function with output_area\n     */\n    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n      /* Is output safe? */\n      safe: true,\n      /* Index of renderer in `output_area.display_order` */\n      index: 0\n    });\n  }\n\n  // register the mime type if in Jupyter Notebook environment and previously unregistered\n  if (root.Jupyter !== undefined) {\n    const events = require('base/js/events');\n    const OutputArea = require('notebook/js/outputarea').OutputArea;\n\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  }\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  const NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    const el = document.getElementById(\"bc69267f-5dbb-440a-a604-56a5cca73d73\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-3.1.1.min.js\"];\n  const css_urls = [];\n\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {\n    }\n  ];\n\n  function run_inline_js() {\n    if (root.Bokeh !== undefined || force === true) {\n          for (let i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\nif (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      const cell = $(document.getElementById(\"bc69267f-5dbb-440a-a604-56a5cca73d73\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));","application/vnd.bokehjs_load.v0+json":""},"metadata":{},"output_type":"display_data"}],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from matplotlib import animation\n","# plt.rcParams['animation.ffmpeg_path'] = '/usr/local/lib/python3.8/dist-packages'\n","import matplotlib.cm as cm\n","from matplotlib.colors import Normalize\n","\n","import neurite as ne\n","import voxelmorph as vxm\n","import tensorflow as tf\n","\n","import os, sys, shutil\n","import nibabel as nib\n","import cv2\n","# from scipy import ndimage\n","# from IPython import display  # Would conflict with Python's display\n","import IPython\n","import logging\n","import warnings\n","\n","sys.path.insert(0, util_dir)\n","from utils import *\n","# from paper_visualization import *\n","\n","from pixelshifting import generateAffineDSA\n","\n","warnings.filterwarnings('ignore')\n","tf.get_logger().setLevel(logging.ERROR)\n","tf.compat.v1.experimental.output_all_intermediates(True)\n","tf.compat.v1.disable_eager_execution()\n","# tf.compat.v1.enable_eager_execution()"]},{"cell_type":"code","execution_count":null,"id":"d3f81719","metadata":{"id":"d3f81719","outputId":"e3118573-8138-4f30-a561-8c370814e32c"},"outputs":[{"name":"stdout","output_type":"stream","text":["4946 100\n","100 94\n","5046 194\n"]}],"source":["folders_train_old = [os.path.join(train_dir, f) for f in sorted(os.listdir(train_dir))\n","                     if not os.path.isfile(os.path.join(train_dir, f))]\n","folders_test_old = [os.path.join(test_dir, f) for f in sorted(os.listdir(test_dir))\n","                    if not os.path.isfile(os.path.join(test_dir, f))]\n","print(len(folders_train_old), len(folders_test_old))\n","\n","folders_train_cm = [os.path.join(cm_train_dir, f) for f in sorted(os.listdir(cm_train_dir))\n","                    if not os.path.isfile(os.path.join(cm_train_dir, f))]\n","folders_test_cm = [os.path.join(cm_test_dir, f) for f in sorted(os.listdir(cm_test_dir))\n","                   if not os.path.isfile(os.path.join(cm_test_dir, f))]\n","print(len(folders_train_cm), len(folders_test_cm))\n","\n","folders_train = folders_train_old + folders_train_cm\n","folders_test = folders_test_old + folders_test_cm\n","\n","print(len(folders_train), len(folders_test))\n","\n","folders_sel = folders_test"]},{"cell_type":"code","execution_count":null,"id":"3417e638","metadata":{"id":"3417e638","outputId":"1ea51fe3-2120-4555-afd8-97653cbdcd1a"},"outputs":[{"data":{"text/plain":["(100, 94)"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["len(folders_test_old), len(folders_test_cm)"]},{"cell_type":"code","execution_count":null,"id":"e27e21c2","metadata":{"id":"e27e21c2"},"outputs":[],"source":["# model_names = ['Naive', 'MinMax', 'MeanMask', 'FilMask', 'ProbMatte']\n","image_shape = (512, 512)\n","\n","def init_hpnet(hp_input):\n","    x = tf.keras.layers.Dense(32, activation='relu')(hp_input)\n","    x = tf.keras.layers.Dense(64, activation='relu')(x)\n","    x = tf.keras.layers.Dense(128, activation='relu')(x)\n","    x = tf.keras.layers.Dense(128, activation='relu')(x)\n","    hypernetwork = tf.keras.Model(hp_input, x, name='hypernetwork')\n","    return hypernetwork\n","\n","def load_model(model_name):\n","    if model_name is 'Naive':\n","        hp_input = tf.keras.Input(shape=[1])\n","        hypernetwork = init_hpnet(hp_input)\n","        model = vxm.networks.VxmDense(image_shape, int_steps=0, hyp_model=hypernetwork)\n","        model_path = os.path.join(root_dir, 'Naive/dsa-hyper-naive.h5')\n","        model.load_weights(model_path)\n","    elif model_name is 'MinMax':\n","        hp_input = tf.keras.Input(shape=[1])\n","        hypernetwork = init_hpnet(hp_input)\n","        model = vxm.networks.VxmDense(image_shape, int_steps=0, bidir=True, hyp_model=hypernetwork)\n","        model_path = os.path.join(root_dir, 'MinMax/dsa_hyper_cycle.h5')\n","        model.load_weights(model_path)\n","    elif model_name is 'MeanMask':\n","        hp_input = tf.keras.Input(shape=[2])\n","        hypernetwork = init_hpnet(hp_input)\n","        model = vxm.networks.VxmDense(image_shape, int_steps=0, hyp_model=hypernetwork)\n","        model_path = os.path.join(root_dir, 'LayerSep-mean-thresh/dsa-hyper-ls.h5')\n","        model.load_weights(model_path)\n","    elif model_name is 'FilMask':\n","        hp_input = tf.keras.Input(shape=[1])\n","        hypernetwork = init_hpnet(hp_input)\n","        model = vxm.networks.VxmDense(image_shape, int_steps=0, hyp_model=hypernetwork)\n","        model_path = os.path.join(root_dir, 'LayerSep-filter/dsa-hyper-ls.h5')\n","        model.load_weights(model_path)\n","    elif model_name is 'ProbMatte':\n","        hp_input = tf.keras.Input(shape=[1])\n","        hypernetwork = init_hpnet(hp_input)\n","        model = vxm.networks.VxmDense(image_shape, int_steps=0, hyp_model=hypernetwork)\n","        model_path = os.path.join(root_dir, 'LayerSep-prob/dsa-hyper-ls.h5')\n","        model.load_weights(model_path)\n","    # print(os.path.exists(model_path))\n","    return model"]},{"cell_type":"code","execution_count":null,"id":"a8c55a79","metadata":{"id":"a8c55a79"},"outputs":[],"source":["def dsa_predict(model_name, xseq_bg, xseq_ct):\n","    if model_name is 'Naive':\n","        hp = [0.7]\n","    elif model_name is 'MinMax':\n","        hp = [0.5]\n","    elif model_name is 'MeanMask':\n","        hp = [0.7, 0]\n","    elif model_name is 'FilMask':\n","        hp = [0.7]\n","    elif model_name is 'ProbMatte':\n","        hp = [0.7]\n","\n","    nx = len(xseq_bg)\n","    hp_seq = np.repeat(np.array([hp]), nx, axis=0)\n","    inputs = [xseq_bg, xseq_ct, hp_seq]\n","\n","    model = models[model_name]\n","    preds = model.predict(inputs, verbose=0)\n","    xseq_mv = preds[0]\n","\n","    dsa_seq = xseq_ct - xseq_mv\n","    return dsa_seq"]},{"cell_type":"code","execution_count":null,"id":"04ac04bb","metadata":{"id":"04ac04bb"},"outputs":[],"source":["def scaling(images):\n","    images = (images - images.min()) / (images.max() - images.min())\n","    images = images * 4095.\n","    return images\n","\n","def matching(image, matchImage):\n","    ## Take the center of the frame to avoid issues with collumnation\n","    offs = 100\n","    lb = 0+offs\n","    ub = 511-offs\n","\n","    firstFrameMean = np.mean(image[0,lb:ub,lb:ub])\n","    firstFrameMeanMatch = np.mean(matchImage[0,lb:ub,lb:ub])\n","\n","    image_centered = image - firstFrameMean\n","    matchImage_centered = matchImage-firstFrameMeanMatch\n","\n","    ratio_std = np.std(matchImage_centered[:,lb:ub,lb:ub]) / np.std(image_centered[:,lb:ub,lb:ub])\n","    image_new = image_centered * ratio_std\n","    image_new = image_new + firstFrameMeanMatch\n","\n","    maximum = np.amax(matchImage)\n","    minimum = np.amin(matchImage)\n","    image_new[image_new > maximum] = maximum\n","    image_new[image_new < minimum] = minimum\n","    return image_new"]},{"cell_type":"code","execution_count":null,"id":"e8beccc5","metadata":{"id":"e8beccc5"},"outputs":[],"source":["def load_xray_seq(folders, i_seq=None, glob_norm=False, filename='input.nii'):\n","    if i_seq is None:\n","        i_seq = np.random.choice(len(folders))\n","\n","    path = os.path.join(folders[i_seq], filename)\n","    xrays_raw = nib.load(path).get_fdata()\n","\n","    xrays = np.moveaxis(xrays_raw, -1, 0)\n","    # if glob_norm:\n","    #     xrays = xrays / 4095.\n","    # else:\n","    #     xrays = (xrays - xrays.min()) / (xrays.max() - xrays.min())\n","    # # xrays = [cv2.resize(xa, dsize=(32, 32), interpolation=cv2.INTER_CUBIC) for xa in xrays]\n","    # # xrays = [cv2.cvtColor(xa, cv2.COLOR_GRAY2RGB) for xa in xrays]\n","    # xrays = np.array(xrays, dtype='float32')\n","    # xrays = xrays[..., None]\n","\n","    return xrays"]},{"cell_type":"code","execution_count":null,"id":"566d9adf","metadata":{"id":"566d9adf"},"outputs":[],"source":["def margin_cropping(xrays, margin=10):\n","    return xrays[:, margin:-margin, margin:-margin]"]},{"cell_type":"code","execution_count":null,"id":"4612b636","metadata":{"id":"4612b636"},"outputs":[],"source":["def out_dsa_cases(xrays):\n","    idx_f0 = 0\n","    nx = xrays.shape[0]\n","\n","    print(xrays.shape, xrays.dtype, xrays.min(), xrays.max())\n","    print(xrays.transpose(1,2,0).shape)\n","    dsa_affine = generateAffineDSA(xrays)\n","    dsa_affine = scaling(dsa_affine)\n","    dsa_affine = margin_cropping(dsa_affine)\n","    dsa_cases=[dsa_affine]\n","\n","    xrays = (xrays - xrays.min()) / (xrays.max() - xrays.min())\n","    xrays = np.array(xrays, dtype='float32')\n","    xrays = xrays[..., None]\n","\n","    xseq_bg = np.repeat(xrays[idx_f0][None], nx, axis=0)\n","    xseq_ct = xrays\n","\n","    # dsa_org = xseq_ct - xseq_bg  # original dsa\n","    # dsa_org = scaling(dsa_org.squeeze())\n","    # dsa_cases = [dsa_org]\n","\n","    for model_name in models.keys():\n","        dsa = dsa_predict(model_name, xseq_bg, xseq_ct)  # predicted dsa\n","        dsa = scaling(dsa.squeeze())\n","        dsa = margin_cropping(dsa)\n","        dsa_cases.append(dsa)\n","\n","    ## Adjust dsa\n","    # dsa_cases[0] = matching(image=dsa_cases[0], matchImage=dsa_cases[3])\n","    matchDSA = np.mean(dsa_cases, axis=0)\n","    for i in range(len(dsa_cases)):\n","        dsa_cases[i] = matching(image=dsa_cases[i], matchImage=matchDSA)\n","\n","    return dsa_cases"]},{"cell_type":"code","execution_count":null,"id":"7abdc47e","metadata":{"id":"7abdc47e"},"outputs":[],"source":["affine = [[0, -1, 0, 0],\n","          [-1, 0, 0, 0],\n","          [0, 0, 1, 0],\n","          [0, 0, 0, 1]]\n","\n","def output_nifti(images, path):\n","    images = np.moveaxis(images, 0, -1)  # change batch axis\n","    image = nib.Nifti1Image(images, affine)\n","    image.to_filename(path)"]},{"cell_type":"code","execution_count":null,"id":"ab408c3d","metadata":{"id":"ab408c3d"},"outputs":[],"source":["def output_single_pool(folders_sel, i_seq=None, prompt=False):\n","    n_seq = len(folders_sel)\n","    if i_seq is None:\n","        i_seq = np.random.randint(n_seq)\n","    if prompt: print(f'# of seqence: {i_seq}')\n","\n","    dst_dir = os.path.join( samples_dir, str(i_seq).zfill(3) )\n","    if not os.path.exists(dst_dir):\n","        os.makedirs(dst_dir)\n","\n","    xrays = load_xray_seq(folders_sel, i_seq)\n","    nx = len(xrays)\n","\n","    nx_max = 25\n","    if nx > nx_max:\n","        indices = np.linspace(0, nx-1, nx_max, endpoint=True, dtype='int64')\n","        xrays = xrays[indices]\n","        nx = nx_max\n","\n","    dsa_cases = out_dsa_cases(xrays)\n","\n","    pool_order = np.random.permutation(2)\n","    if prompt: print(f'pool order: {pool_order}')\n","    sep_wid = 4\n","    #row1 = np.concatenate((dsa_cases[pool_order[0]], np.zeros((nx,512,sep_wid)), dsa_cases[pool_order[1]]), axis=2)\n","    #row2 = np.concatenate((dsa_cases[pool_order[2]], np.zeros((nx,512,sep_wid)), dsa_cases[pool_order[3]]), axis=2)\n","    #pool_dsa_seq = np.concatenate((row1, np.zeros((nx,sep_wid,row1.shape[-1])), row2), axis=1)\n","    H, W = dsa_cases[0].shape[1:3]\n","    pool_dsa_seq = np.concatenate((dsa_cases[pool_order[0]],\n","                                   np.zeros((nx,H,sep_wid)),\n","                                   dsa_cases[pool_order[1]]), axis=2)\n","    if prompt: print(f'pool image shape: {pool_dsa_seq.shape}')\n","\n","    output_nifti(pool_dsa_seq, os.path.join(dst_dir, 'pool_dsa.nii'))\n","\n","    with open(os.path.join(dst_dir, \"pool_order.txt\"), \"w\") as file:\n","        for idx in pool_order:\n","            file.write(\" \".join(str(idx)) + \"\\n\") # works with any number of elements in a line\n","\n","    with open(os.path.join(dst_dir, \"src_dir.txt\"), \"w\") as file:\n","        file.write(folders_sel[i_seq])"]},{"cell_type":"markdown","id":"901edd65","metadata":{"id":"901edd65"},"source":["## Output test samples"]},{"cell_type":"code","execution_count":null,"id":"7963a7ed","metadata":{"id":"7963a7ed"},"outputs":[],"source":["models = {\n","    #'Naive': load_model('Naive'),\n","    #'MinMax': load_model('MinMax'),\n","    'FilMask': load_model('FilMask')\n","}"]},{"cell_type":"code","execution_count":null,"id":"64561a6c","metadata":{"id":"64561a6c","outputId":"55300fda-ed7b-49ef-c4d0-e58eed9be225"},"outputs":[{"name":"stdout","output_type":"stream","text":["folder has been created\n"]}],"source":["samples_dir = os.path.join(workspace, 'likert_samples')\n","\n","if os.path.exists(samples_dir):\n","    shutil.rmtree(samples_dir)\n","\n","if not os.path.exists(samples_dir):\n","    os.makedirs(samples_dir)\n","    print(\"folder has been created\")"]},{"cell_type":"code","execution_count":null,"id":"45277d90","metadata":{"id":"45277d90"},"outputs":[],"source":["N_seq = len(folders_sel)\n","all_idxes = [*range(N_seq)]\n","\n","old_dir = os.path.join(workspace, 'test_samples')\n","\n","if os.path.exists(old_dir):\n","    old_idxes = [int(f) for f in sorted(os.listdir(old_dir))\n","                if not os.path.isfile(os.path.join(old_dir, f))]\n","    fil_idxes = [i for i in all_idxes if i not in old_idxes]\n","else:\n","    fil_idxes = all_idxes"]},{"cell_type":"code","execution_count":null,"id":"4cdbeacb","metadata":{"id":"4cdbeacb","outputId":"3438c902-190a-4d96-bca1-b10fbe2d4487"},"outputs":[{"name":"stdout","output_type":"stream","text":["(23, 512, 512) float64 399.0 4096.0\n","(512, 512, 23)\n","I am on frame 0.\n","There are 4763 matches.\n","[[ 1. -0.  0.]\n"," [ 0.  1.  0.]]\n","I am on frame 1.\n","There are 4763 matches.\n","[[ 1.00004511e+00 -9.37101141e-04  5.93274859e-01]\n"," [ 9.37101141e-04  1.00004511e+00 -1.12714912e+00]]\n","I am on frame 2.\n","There are 4763 matches.\n","[[ 9.99601971e-01 -1.01736855e-03  9.82672412e-01]\n"," [ 1.01736855e-03  9.99601971e-01 -1.56770389e+00]]\n","I am on frame 3.\n","There are 4763 matches.\n","[[ 9.99609374e-01 -6.27644413e-04  9.59882453e-01]\n"," [ 6.27644413e-04  9.99609374e-01 -1.46584005e+00]]\n","I am on frame 4.\n","There are 4763 matches.\n","[[ 9.99212953e-01 -1.28502688e-03  1.18612839e+00]\n"," [ 1.28502688e-03  9.99212953e-01 -1.67494405e+00]]\n","I am on frame 5.\n","There are 4763 matches.\n","[[ 9.99811968e-01 -1.86190245e-03  1.35334834e+00]\n"," [ 1.86190245e-03  9.99811968e-01 -2.19568253e+00]]\n","I am on frame 6.\n","There are 4763 matches.\n","[[ 1.00166169e+00 -2.43113257e-04  7.50487137e-01]\n"," [ 2.43113257e-04  1.00166169e+00 -2.28830975e+00]]\n","I am on frame 7.\n","There are 4763 matches.\n","[[ 1.00096230e+00 -1.65191642e-03  1.14021706e+00]\n"," [ 1.65191642e-03  1.00096230e+00 -2.55916068e+00]]\n","I am on frame 8.\n","There are 4763 matches.\n","[[ 9.99937863e-01 -1.14067966e-03  1.38254740e+00]\n"," [ 1.14067966e-03  9.99937863e-01 -1.99927543e+00]]\n","I am on frame 9.\n","There are 4763 matches.\n","[[ 1.00102731e+00 -8.78473249e-04  1.33164735e+00]\n"," [ 8.78473249e-04  1.00102731e+00 -1.94014891e+00]]\n","I am on frame 10.\n","There are 4763 matches.\n","[[ 1.00056665e+00 -4.25232604e-04  1.05985113e+00]\n"," [ 4.25232604e-04  1.00056665e+00 -1.71134552e+00]]\n","I am on frame 11.\n","There are 4763 matches.\n","[[ 1.00030422e+00 -1.94337623e-04  1.11532056e+00]\n"," [ 1.94337623e-04  1.00030422e+00 -1.46180002e+00]]\n","I am on frame 12.\n","There are 4763 matches.\n","[[ 1.00070229e+00 -1.49017459e-03  1.16142531e+00]\n"," [ 1.49017459e-03  1.00070229e+00 -1.91382063e+00]]\n","I am on frame 13.\n","There are 4763 matches.\n","[[ 9.99937422e-01 -6.41179299e-04  4.38415214e-01]\n"," [ 6.41179299e-04  9.99937422e-01 -3.21094738e-01]]\n","I am on frame 14.\n","There are 4763 matches.\n","[[ 1.00069850e+00 -8.80357826e-04  1.79995244e-01]\n"," [ 8.80357826e-04  1.00069850e+00 -6.02787813e-01]]\n","I am on frame 15.\n","There are 4763 matches.\n","[[ 1.00110285 -0.00194563  0.40173479]\n"," [ 0.00194563  1.00110285 -1.25567217]]\n","I am on frame 16.\n","There are 4763 matches.\n","[[ 1.0014775  -0.00217347  0.36211768]\n"," [ 0.00217347  1.0014775  -1.47100568]]\n","I am on frame 17.\n","There are 4763 matches.\n","[[ 1.00126931 -0.00276095  0.45488501]\n"," [ 0.00276095  1.00126931 -1.52960941]]\n","I am on frame 18.\n","There are 4763 matches.\n","[[ 1.00180428 -0.002991    1.00597003]\n"," [ 0.002991    1.00180428 -2.81764263]]\n","I am on frame 19.\n","There are 4763 matches.\n","[[ 1.00212962e+00 -2.88959605e-03  1.46645921e+00]\n"," [ 2.88959605e-03  1.00212962e+00 -3.11002475e+00]]\n","I am on frame 20.\n","There are 4763 matches.\n","[[ 1.00213580e+00 -2.89793736e-03  1.84291577e+00]\n"," [ 2.89793736e-03  1.00213580e+00 -3.28050928e+00]]\n","I am on frame 21.\n","There are 4763 matches.\n","[[ 1.00118815 -0.00195797  1.04162429]\n"," [ 0.00195797  1.00118815 -1.77615124]]\n","I am on frame 22.\n","There are 4763 matches.\n","[[ 1.00189501 -0.00236959  1.24368029]\n"," [ 0.00236959  1.00189501 -2.35416373]]\n","I am working on frame 0\n","I am working on frame 1\n","I am working on frame 2\n","I am working on frame 3\n","I am working on frame 4\n","I am working on frame 5\n","I am working on frame 6\n","I am working on frame 7\n","I am working on frame 8\n","I am working on frame 9\n","I am working on frame 10\n","I am working on frame 11\n","I am working on frame 12\n","I am working on frame 13\n","I am working on frame 14\n","I am working on frame 15\n","I am working on frame 16\n","I am working on frame 17\n","I am working on frame 18\n","I am working on frame 19\n","I am working on frame 20\n","I am working on frame 21\n","I am working on frame 22\n","(512, 512, 23) float64 0.0 4096.0\n","The shape of the first frame is (512, 512).\n",".\n"]}],"source":["tmp_idxes = np.random.choice(len(fil_idxes), size=50, replace=False)\n","indices_seq = [fil_idxes[i] for i in tmp_idxes]\n","\n","for (i, i_seq) in enumerate(indices_seq):\n","    IPython.display.clear_output(wait=True)\n","    output_single_pool(folders_sel, i_seq=i_seq, prompt=False)\n","    if (i+1) % 10 != 0:\n","        print('.', end='')\n","    else:\n","        print('.')"]},{"cell_type":"code","execution_count":null,"id":"d1fd5212","metadata":{"id":"d1fd5212"},"outputs":[],"source":["# output_single_pool(folders_sel, i_seq=134, prompt=True)"]},{"cell_type":"code","execution_count":null,"id":"37950c3b","metadata":{"id":"37950c3b"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}